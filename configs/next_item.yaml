# runner type tag
_type_: test.next_item
# wandb project
project: recsys.synth.mdp.next_item_test_scores
# wandb logging
log: True

seed: 42
cuda_device: ...

generation_phase:
  epochs: 1
  episodes_per_epoch: 3000
  samples_per_epoch: 10000
  use_cache: true

learning_phase:
  epochs: 250
  eval_schedule: 5
  eval_episodes: 20

env:
  _base_: $_base.env
  n_users: 100
  n_items: 1000
  max_episode_len: [50, 10]
  embeddings:
    n_dims: 8
    users: $_base.embeddings.10_clusters_for_8_dims
    items: $_base.embeddings.20_clusters_for_8_dims
  user_state:
    _base_: $_base.user_states.default
    base_satiation_speed: [0.1, .4]
    satiation_drift: .2
    relevance_boosting: [0.2, 4.0]
    discrete_actions:
      - [0.2, 0.08]
      - [0.37, 0.1]
      - [0.58, 0.03]
      - [0.75, 0.05]

framestack:
  size: 10
  empty_rating: [.6, 3]

mdp:
  ratings_column: relevance_int
  framestack_size: 10
  reward_function_name: ones_reward #relevance_based_reward #"ones_reward"
  action_function_name: next_item_action
  episode_splitter_name: interaction_interruption #full_user_interaction #"interaction_interruption"

generation_model:
  _base_: $_base.models.discrete_random
  batch_size: 32

eval_model:
  _base_: $_base.models.discrete_cql
  batch_size: 1024

scoring:
  top_k: 10
  metrics: [ndcg, stat_hitrate, PC, ihitrate]
  tresh: [0.7, 0.5, 0.9]
  prediction_type: discrete

zoya_settings:
  top_k: 10
  ratings_column: relevance_int
  mdp_settings:
    framestack_size: 10
    reward_function_name: ones_reward #relevance_based_reward #"ones_reward"
    action_function_name: next_item_action
    episode_splitter_name: interaction_interruption #full_user_interaction #"interaction_interruption"

  scorer:
    metrics: [ndcg, stat_hitrate, PC, ihitrate]
    tresh: [0.7, 0.5, 0.9]
    prediction_type: discrete

  algo_settings:
    general_parameters:
      algo: DCQL
      batch_size: 1024
      use_gpu: False

    model_parameters:
      use_als: False
      emb_dim: 16
      hid_dim: 256
      memory_size: 10
      feature_size: 512
      #drr adrr
      state_repr_name: full_history
      freeze_emb: False
      attention_hidden_size: 32
      state_keys:
        - user
        - item
#        - score

wandb_init: $_base.wandb_init
cache:
  cache_root: cache
  enable: ???
  experiment_config: ???
  keep_last_n_experiments: 4
