# runner type tag
_type_: test.mdp_nip_reset
# wandb project
project: recsys.synth.mdp.next_item
# wandb logging
log: True

seed: 42
cuda_device: ...

generation:
  epochs: 1
  episodes_per_epoch: 1000
  samples_per_epoch: 10000

learning:
  epochs: 500
  eval_schedule: 5
  eval_episodes: 20

env:
  global_config: ???
  seed: ???
  n_users: 100
  n_items: 100
  max_episode_len: [40, 20]
  embeddings:
    n_dims: 8
    users:
      _base_: embeddings.clusters
      n_clusters: 10
      intra_cluster_noise_scale: 0.15
      min_l2_dist: 0.3
    items:
      _base_: embeddings.clusters
      n_clusters: 10
      cluster_sampling_weight:
        0: 1
      intra_cluster_noise_scale: 0.15
      min_l2_dist: 0.
  user_state:
    base_satiation: 0.15
    base_satiation_speed: [0.04, .4]
    satiation_drift: .2
    item_listening_trace_decay: .9
    item_repeat_penalty_power: .15
    early_stop_delta: 0.005
    similarity_metric: l2
    item_to_cluster_classification: softmax
    relevance_boosting: [0.2, 4.0]
    boosting_softness: [2.0, 3.0]
    discrete_actions:
      - [0.2, 0.08]
      - [0.37, 0.05]
      - [0.58, 0.03]
      - [0.75, 0.1]

zoya_settings:
  top_k: 10
  ratings_column: relevance_int
  mdp_settings:
    framestack_size: 10
    reward_function_name: "relevance_based_reward"
    action_function_name: "next_item_action"
    episode_splitter_name: "interaction_interruption"


  scorer:
    metrics: ['ndcg', 'stat_hitrate', 'PC', 'ihitrate']
    tresh: [0.7, 0.5, 0.9]
    prediction_type: "discrete"

  algo_settings:
    general_parameters:
      algo: DCQL
      batch_size: 1024
      use_gpu: False

    model_parameters:
      use_als: False
      user_num: 100
      item_num: 100
      emb_dim: 16
      hid_dim: 32
      memory_size: 10
      feature_size: 512
      state_repr_name: "full_history" #drr adrr
      freeze_emb: False
      attention_hidden_size: 32
      state_keys: ['user','item'] #['user','item','score']

model:
  _base_: models.random
  batch_size: 32

models:
  random:
    _type_: model.random
    seed: ???
    n_actions: ???
    batch_size: ???
  cql:
    _type_: d3rlpy.cql
    _base_: default
    actor_learning_rate: 1e-3
    critic_learning_rate: 3e-3
    temp_learning_rate: 1e-4
    alpha_learning_rate: 1e-4
    alpha_threshold: 10.0
    conservative_weight: 5.0
    initial_temperature: 1.0
    initial_alpha: 1.0
    n_action_samples: 10
    soft_q_backup: False
  bc:
    _type_: d3rlpy.bc
    _base_: default
    learning_rate: 5e-4
  sac:
    _type_: d3rlpy.sac
    _base_: default
  ddpg:
    _type_: d3rlpy.ddpg
    _base_: default
    temp_learning_rate: 1e-4
    initial_temperature: 1.0
  discrete_cql:
    _type_: d3rlpy.discrete_cql
    _base_: default
  sdac:
    _type_: d3rlpy.sdac
    _base_: default
  discrete_sac:
    _type_: d3rlpy.discrete_sac
    _base_: default
  default:
    actor_learning_rate: 1e-4
    critic_learning_rate: 3e-4
    temp_learning_rate: 1e-4  #?
    alpha_learning_rate: 1e-4 # ?
    q_func_factory: "mean"
    batch_size: 256
    n_frames: 1
    n_steps: 1
    gamma: 0.99
    tau: 0.005
    n_critics: 2
    initial_temperature: 1.0  #?
    initial_alpha: 1.0  #?
    alpha_threshold: 10.0 # ?
    conservative_weight: 5.0 # ?
    n_action_samples: 10  #?
    soft_q_backup: False  #?

embeddings:
  random:
    _type_: embeddings.random
    seed: ???
    n_dims: ???

  clusters:
    _type_: embeddings.clusters
    seed: ???
    n_dims: ???
    n_clusters: 4
    intra_cluster_noise_scale: 0.05
    n_dissimilar_dims_required: 3
    min_dim_delta: 0.3
    min_l2_dist: 0.1
    max_generation_tries: 20000

# additional params for wandb.init
wandb_init:
  name: ...
  group: ...
