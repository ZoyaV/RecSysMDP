{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aa973ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "824d7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DBC_pure_best.yaml\", 'r') as file:\n",
    "    # Load the YAML data from the file\n",
    "    yaml_data = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0534571",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_config = yaml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a3c5993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_random\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n",
      "--------------------->\n",
      "environments/env_best\n",
      "environments/env_best/train_data.csv\n",
      "environments/env_best/train_data.csv\n",
      "--------------------->\n"
     ]
    }
   ],
   "source": [
    "# Словарь возможных значений параметров\n",
    "parameters_dict = {\n",
    "    'env_path': ['environments/env_random','environments/env_best'],\n",
    "    'algo': ['DBC', 'DCQL', 'SDAC', 'DSAC'],\n",
    "    'episode_splitter_name':  ['full_user_interaction','interaction_interruption'],                     \n",
    "    'freeze_emb': [False, True]\n",
    "}\n",
    "\n",
    "# Получаем все возможные комбинации параметров\n",
    "combinations = list(itertools.product(*parameters_dict.values()))\n",
    "\n",
    "# Итерируемся по всем комбинациям\n",
    "for i, combination in enumerate(combinations):\n",
    "    # Создаем новую конфигурацию на основе исходной\n",
    "    new_config = source_config.copy()\n",
    "\n",
    "    # Задаем новые значения параметров\n",
    "    for parameter, value in zip(parameters_dict.keys(), combination):\n",
    "        if parameter == 'algo':\n",
    "            new_config['experiment']['algo_settings']['general_parametrs'][parameter] = value\n",
    "        elif parameter == 'freeze_emb':\n",
    "            new_config['experiment']['algo_settings']['model_parametrs'][parameter] = value\n",
    "        elif parameter == 'episode_splitter_name':\n",
    "            new_config['experiment']['mdp_settings'][parameter] = value\n",
    "        else:  # parameter == 'env_path'\n",
    "            new_config[parameter] = value\n",
    "    new_config['group_name'] = str(combination)\n",
    "    print(\"--------------------->\")\n",
    "    print(new_config['env_path'])\n",
    "    print(new_config['experiment']['data_path'] )\n",
    "    new_config['experiment']['data_path'] =  new_config['experiment']['data_path']\\\n",
    "                        .replace('environments/env_random', new_config['env_path'])\n",
    "    new_config['experiment']['test_data_path'] = new_config['experiment']['test_data_path']\\\n",
    "                        .replace('environments/env_random', new_config['env_path'])\n",
    "    \n",
    "    print(new_config['experiment']['data_path'] )\n",
    "    print(\"--------------------->\")\n",
    "\n",
    "    # Сохраняем новую конфигурацию в файл\n",
    "    with open(f'config_{i}.yaml', 'w') as config_file:\n",
    "        yaml.safe_dump(new_config, config_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aea82ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters_dict = {\n",
    "                    'env_path': ['environments/env_random','environments/env_best'],\n",
    "                    'algo': ['DBC', 'DCQL', 'SDAC', 'DSAC'],\n",
    "                    'episode_splitter_name':  ['full_user_interaction','interaction_interruption'],                     \n",
    "                    'freeze_emb': [False, True]}\n",
    "\n",
    "\n",
    "old_dict = {\n",
    "                    'env_path': 'environments/env_random',\n",
    "                    'algo': 'DBC',\n",
    "                    'episode_splitter_name': 'full_user_interaction',                     \n",
    "                    'freeze_emb': False}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0088d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "parameters_dict = {\n",
    "    'env_path': ['environments/env_random','environments/env_best'],\n",
    "    'algo': ['DBC', 'DCQL', 'SDAC', 'DSAC'],\n",
    "    'episode_splitter_name':  ['full_user_interaction','interaction_interruption'],                     \n",
    "    'freeze_emb': [False, True]\n",
    "}\n",
    "\n",
    "# Получаем все возможные комбинации значений параметров\n",
    "combinations = list(itertools.product(*parameters_dict.values()))\n",
    "\n",
    "# Создаем список словарей, каждый из которых представляет одну комбинацию параметров\n",
    "result = [dict(zip(parameters_dict.keys(), combination)) for combination in combinations]\n",
    "\n",
    "# Преобразуем каждый словарь в список строк формата \"'ключ':'параметр'\"\n",
    "result = [[f\"'{k}':'{v}'\" for k, v in combination.items()] for combination in result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c541bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'name': 'eval_on_cases_3', 'group_name': 'DBC_pure_best', 'seed': 42, 'use_wandb': True, 'eval_online': True, 'env_path': 'environments/env_random', 'looking_for': '0,1,5', 'experiment': {'top_k': 10, 'data_path': 'environments/env_best/train_data.csv', 'test_data_path': 'environments/env_best/test_data.csv', 'col_mapping': {'user_col_name': 'user_idx', 'item_col_name': 'item_idx', 'reward_col_name': 'relevance_int', 'timestamp_col_name': 'timestamp'}, 'mdp_settings': {'framestack_size': 10, 'reward_function_name': 'relevance_based_reward', 'action_function_name': 'next_item_action', 'episode_splitter_name': 'interaction_interruption', 'history_keys': ['framestack', 'user_id']}, 'scorer': {'metrics': ['ndcg', 'PC', 'ihitrate', 'stat_hitrate'], 'tresh': '[0.5, 0.7]', 'prediction_type': 'discrete'}, 'algo_settings': {'n_epochs': 300, 'general_parametrs': {'algo': 'DSAC', 'batch_size': 1024, 'use_gpu': False}, 'model_parametrs': {'use_als': False, 'user_num': 100, 'item_num': 100, 'emb_dim': 5, 'hid_dim': 256, 'memory_size': 10, 'feature_size': 512, 'state_repr_name': 'full_history', 'freeze_emb': True, 'attention_hidden_size': 32}}}}\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(yaml_data).replace(\"'algo': 'DBC'\", \"'algo':'DCQL'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46900145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def dict_product(d):\n",
    "    keys = d.keys()\n",
    "    for element in itertools.product(*d.values()):\n",
    "        yield dict(zip(keys, element))\n",
    "\n",
    "\n",
    "def recursive_dict_product(d):\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            for dict_comb in recursive_dict_product(v):\n",
    "                yield {**{k: dict_comb}}\n",
    "        else:\n",
    "            for val_comb in dict_product({k: v}):\n",
    "                yield val_comb\n",
    "\n",
    "\n",
    "def generate_yaml(base_config, parameters_dict, output_path):\n",
    "    for i, params in enumerate(recursive_dict_product(parameters_dict)):\n",
    "        new_config = deepcopy(base_config)\n",
    "        group_name = 'EXP'\n",
    "\n",
    "        for key, value in params.items():\n",
    "            keys = key.split('.')\n",
    "            last_key = keys.pop()\n",
    "            dict_ = new_config\n",
    "            for k in keys:\n",
    "                dict_ = dict_[k]\n",
    "            dict_[last_key] = value\n",
    "            group_name += f'_{key.replace(\".\", \"_\")}_{value}'\n",
    "\n",
    "        new_config['group_name'] = group_name\n",
    "        with open(f'{output_path}/config_{i}.yaml', 'w') as file:\n",
    "            yaml.dump(new_config, file)\n",
    "\n",
    "\n",
    "base_config = yaml.load(open('DBC_pure_best.yaml'), Loader=yaml.FullLoader)\n",
    "#base_config = {'name': 'eval_on_cases', 'group_name': 'DBC_pure_best', 'seed': 42, ...}\n",
    "#params_to_iterate = {'group_name': 'DBC_pure_best', 'env_path': ['environments/env_random','environments/env_best'], ...}\n",
    "output_dir = \"./\"  # replace with your directory path\n",
    "\n",
    "generate_yaml(base_config, params_to_iterate, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef3847f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env_path\n",
      "['environments/env_random', 'environments/env_best']\n",
      "env_path\n",
      "['environments/env_random', 'environments/env_best']\n",
      "algo\n",
      "['DBC', 'DCQL', 'SDAC', 'DSAC']\n",
      "algo\n",
      "['DBC', 'DCQL', 'SDAC', 'DSAC']\n",
      "algo\n",
      "['DBC', 'DCQL', 'SDAC', 'DSAC']\n",
      "algo\n",
      "['DBC', 'DCQL', 'SDAC', 'DSAC']\n",
      "episode_splitter_name\n",
      "['full_user_interaction', 'interaction_interruption']\n",
      "episode_splitter_name\n",
      "['full_user_interaction', 'interaction_interruption']\n",
      "freeze_emb\n",
      "[False, True]\n",
      "freeze_emb\n",
      "[False, True]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [63], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m new_str \u001b[38;5;241m=\u001b[39m deepcopy(base_yaml)\n\u001b[1;32m     28\u001b[0m group_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEXP\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m old, new \u001b[38;5;129;01min\u001b[39;00m combo:\n\u001b[1;32m     30\u001b[0m     new_str \u001b[38;5;241m=\u001b[39m new_str\u001b[38;5;241m.\u001b[39mreplace(old, new)\n\u001b[1;32m     31\u001b[0m     group_name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Преобразуем базовый yaml в строку\n",
    "base_yaml = yaml.dump(base_config)\n",
    "\n",
    "# Функция для генерации всех возможных замен\n",
    "def generate_replacements(params_dict, prefix=''):\n",
    "    for k, v in params_dict.items():\n",
    "        key = f\"{prefix}{k}': \"\n",
    "        if isinstance(v, dict):\n",
    "            yield from generate_replacements(v, prefix=key)\n",
    "        else:\n",
    "            for value in v:\n",
    "                print(k)\n",
    "                print(params_dict[k])\n",
    "                if isinstance(value, str):\n",
    "                   # print(key)\n",
    "                   # print(f\"{k}:'{old_dict[k]}'\",  f\"{k}:'{value}'\")\n",
    "                    yield (f\"{k}:'{old_dict[k]}'\",  f\"{k}:'{value}'\")\n",
    "                else:\n",
    "                    yield (f\"{k}:'{old_dict[k]}'\" , k +\":\"+ str(value))\n",
    "\n",
    "# Генерируем все возможные замены\n",
    "replacements = list(generate_replacements(parameters_dict))\n",
    "\n",
    "# Перебираем все комбинации замен\n",
    "for i, combo in enumerate(itertools.product(*replacements)):\n",
    "    # Создаем новую строку, заменяя параметры на новые значения\n",
    "    new_str = deepcopy(base_yaml)\n",
    "    group_name = 'EXP'\n",
    "    for old, new in combo:\n",
    "        new_str = new_str.replace(old, new)\n",
    "        group_name += f'_{new}'\n",
    "\n",
    "    # Преобразуем обратно в yaml\n",
    "    new_yaml = yaml.load(new_str, Loader=yaml.FullLoader)\n",
    "\n",
    "    # Обновляем group_name\n",
    "    new_yaml['group_name'] = group_name\n",
    "\n",
    "    # Сохраняем новый yaml файл\n",
    "    with open(f'config_{i}.yaml', 'w') as file:\n",
    "        yaml.dump(new_yaml, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65e33eb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m old, new \u001b[38;5;129;01min\u001b[39;00m combo:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(old, new)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for old, new in combo:\n",
    "    print(old, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a8c6ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"env_path:'environments/env_random'\", \"env_path:'environments/env_random'\"),\n",
       " (\"env_path:'environments/env_random'\", \"env_path:'environments/env_best'\"),\n",
       " (\"algo:'DBC'\", \"algo:'DBC'\"),\n",
       " (\"algo:'DBC'\", \"algo:'DCQL'\"),\n",
       " (\"algo:'DBC'\", \"algo:'SDAC'\"),\n",
       " (\"algo:'DBC'\", \"algo:'DSAC'\"),\n",
       " (\"episode_splitter_name:'full_user_interaction'\",\n",
       "  \"episode_splitter_name:'full_user_interaction'\"),\n",
       " (\"episode_splitter_name:'full_user_interaction'\",\n",
       "  \"episode_splitter_name:'interaction_interruption'\"),\n",
       " (\"freeze_emb:'False'\", 'freeze_emb:False'),\n",
       " (\"freeze_emb:'False'\", 'freeze_emb:True')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d2e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
